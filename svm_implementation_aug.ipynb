{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, matthews_corrcoef\n",
    "\n",
    "\n",
    "tf.keras.utils.set_random_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': ['S'], 'R': ['Q', 'K'], 'N': ['D', 'H', 'S'], 'D': ['N', 'E'], 'C': [], 'Q': ['R', 'E', 'K'], 'E': ['D', 'Q', 'K'], 'G': [], 'H': ['N', 'Y'], 'I': ['L', 'M', 'V'], 'L': ['I', 'M', 'V'], 'K': ['R', 'Q', 'E'], 'M': ['I', 'L', 'V'], 'F': ['W', 'Y'], 'P': [], 'S': ['A', 'N', 'T'], 'T': ['S'], 'W': ['F', 'Y'], 'Y': ['H', 'F', 'W'], 'V': ['I', 'L', 'M']}\n"
     ]
    }
   ],
   "source": [
    "# Define BLOSUM62 matrix as a dictionary of dictionaries\n",
    "blosum62 = {\n",
    "    'A': {'A': 4, 'R': -1, 'N': -2, 'D': -2, 'C': 0, 'Q': -1, 'E': -1, 'G': 0, 'H': -2, 'I': -1, 'L': -1, 'K': -1, 'M': -1, 'F': -2, 'P': -1, 'S': 1, 'T': 0, 'W': -3, 'Y': -2, 'V': 0},\n",
    "    'R': {'A': -1, 'R': 5, 'N': 0, 'D': -2, 'C': -3, 'Q': 1, 'E': 0, 'G': -2, 'H': 0, 'I': -3, 'L': -2, 'K': 2, 'M': -1, 'F': -3, 'P': -2, 'S': -1, 'T': -1, 'W': -3, 'Y': -2, 'V': -3},\n",
    "    'N': {'A': -2, 'R': 0, 'N': 6, 'D': 1, 'C': -3, 'Q': 0, 'E': 0, 'G': 0, 'H': 1, 'I': -3, 'L': -3, 'K': 0, 'M': -2, 'F': -3, 'P': -2, 'S': 1, 'T': 0, 'W': -4, 'Y': -2, 'V': -3},\n",
    "    'D': {'A': -2, 'R': -2, 'N': 1, 'D': 6, 'C': -3, 'Q': 0, 'E': 2, 'G': -1, 'H': -1, 'I': -3, 'L': -4, 'K': -1, 'M': -3, 'F': -3, 'P': -1, 'S': 0, 'T': -1, 'W': -4, 'Y': -3, 'V': -3},\n",
    "    'C': {'A': 0, 'R': -3, 'N': -3, 'D': -3, 'C': 9, 'Q': -3, 'E': -4, 'G': -3, 'H': -3, 'I': -1, 'L': -1, 'K': -3, 'M': -1, 'F': -2, 'P': -3, 'S': -1, 'T': -1, 'W': -2, 'Y': -2, 'V': -1},\n",
    "    'Q': {'A': -1, 'R': 1, 'N': 0, 'D': 0, 'C': -3, 'Q': 5, 'E': 2, 'G': -2, 'H': 0, 'I': -3, 'L': -2, 'K': 1, 'M': 0, 'F': -3, 'P': -1, 'S': 0, 'T': -1, 'W': -2, 'Y': -1, 'V': -2},\n",
    "    'E': {'A': -1, 'R': 0, 'N': 0, 'D': 2, 'C': -4, 'Q': 2, 'E': 5, 'G': -2, 'H': 0, 'I': -3, 'L': -3, 'K': 1, 'M': -2, 'F': -3, 'P': -1, 'S': 0, 'T': -1, 'W': -3, 'Y': -2, 'V': -2},\n",
    "    'G': {'A': 0, 'R': -2, 'N': 0, 'D': -1, 'C': -3, 'Q': -2, 'E': -2, 'G': 6, 'H': -2, 'I': -4, 'L': -4, 'K': -2, 'M': -3, 'F': -3, 'P': -2, 'S': 0, 'T': -2, 'W': -2, 'Y': -3, 'V': -3},\n",
    "    'H': {'A': -2, 'R': 0, 'N': 1, 'D': -1, 'C': -3, 'Q': 0, 'E': 0, 'G': -2, 'H': 8, 'I': -3, 'L': -3, 'K': -1, 'M': -2, 'F': -1, 'P': -2, 'S': -1, 'T': -2, 'W': -2, 'Y': 2, 'V': -3},\n",
    "    'I': {'A': -1, 'R': -3, 'N': -3, 'D': -3, 'C': -1, 'Q': -3, 'E': -3, 'G': -4, 'H': -3, 'I': 4, 'L': 2, 'K': -3, 'M': 1, 'F': 0, 'P': -3, 'S': -2, 'T': -1, 'W': -3, 'Y': -1, 'V': 3},\n",
    "    'L': {'A': -1, 'R': -2, 'N': -3, 'D': -4, 'C': -1, 'Q': -2, 'E': -3, 'G': -4, 'H': -3, 'I': 2, 'L': 4, 'K': -2, 'M': 2, 'F': 0, 'P': -3, 'S': -2, 'T': -1, 'W': -2, 'Y': -1, 'V': 1},\n",
    "    'K': {'A': -1, 'R': 2, 'N': 0, 'D': -1, 'C': -3, 'Q': 1, 'E': 1, 'G': -2, 'H': -1, 'I': -3, 'L': -2, 'K': 5, 'M': -1, 'F': -3, 'P': -1, 'S': 0, 'T': -1, 'W': -3, 'Y': -2, 'V': -2},\n",
    "    'M': {'A': -1, 'R': -1, 'N': -2, 'D': -3, 'C': -1, 'Q': 0, 'E': -2, 'G': -3, 'H': -2, 'I': 1, 'L': 2, 'K': -1, 'M': 5, 'F': 0, 'P': -2, 'S': -1, 'T': -1, 'W': -1, 'Y': -1, 'V': 1},\n",
    "    'F': {'A': -2, 'R': -3, 'N': -3, 'D': -3, 'C': -2, 'Q': -3, 'E': -3, 'G': -3, 'H': -1, 'I': 0, 'L': 0, 'K': -3, 'M': 0, 'F': 6, 'P': -4, 'S': -2, 'T': -2, 'W': 1, 'Y': 3, 'V': -1},\n",
    "    'P': {'A': -1, 'R': -2, 'N': -2, 'D': -1, 'C': -3, 'Q': -1, 'E': -1, 'G': -2, 'H': -2, 'I': -3, 'L': -3, 'K': -1, 'M': -2, 'F': -4, 'P': 7, 'S': -1, 'T': -1, 'W': -4, 'Y': -3, 'V': -2},\n",
    "    'S': {'A': 1, 'R': -1, 'N': 1, 'D': 0, 'C': -1, 'Q': 0, 'E': 0, 'G': 0, 'H': -1, 'I': -2, 'L': -2, 'K': 0, 'M': -1, 'F': -2, 'P': -1, 'S': 4, 'T': 1, 'W': -3, 'Y': -2, 'V': -2},\n",
    "    'T': {'A': 0, 'R': -1, 'N': 0, 'D': -1, 'C': -1, 'Q': -1, 'E': -1, 'G': -2, 'H': -2, 'I': -1, 'L': -1, 'K': -1, 'M': -1, 'F': -2, 'P': -1, 'S': 1, 'T': 5, 'W': -2, 'Y': -2, 'V': 0},\n",
    "    'W': {'A': -3, 'R': -3, 'N': -4, 'D': -4, 'C': -2, 'Q': -2, 'E': -3, 'G': -2, 'H': -2, 'I': -3, 'L': -2, 'K': -3, 'M': -1, 'F': 1, 'P': -4, 'S': -3, 'T': -2, 'W': 11, 'Y': 2, 'V': -3},\n",
    "    'Y': {'A': -2, 'R': -2, 'N': -2, 'D': -3, 'C': -2, 'Q': -1, 'E': -2, 'G': -3, 'H': 2, 'I': -1, 'L': -1, 'K': -2, 'M': -1, 'F': 3, 'P': -3, 'S': -2, 'T': -2, 'W': 2, 'Y': 7, 'V': -1},\n",
    "    'V': {'A': 0, 'R': -3, 'N': -3, 'D': -3, 'C': -1, 'Q': -2, 'E': -2, 'G': -3, 'H': -3, 'I': 3, 'L': 1, 'K': -2, 'M': 1, 'F': -1, 'P': -2, 'S': -2, 'T': 0, 'W': -3, 'Y': -1, 'V': 4}\n",
    "}\n",
    "\n",
    "def create_conservative_dict(matrix, threshold=1):\n",
    "    \"\"\"Create a substitution dictionary based on a given substitution matrix and threshold.\"\"\"\n",
    "    substitution_dict = {}\n",
    "    for aa1 in matrix:\n",
    "        substitution_dict[aa1] = [aa2 for aa2, score in matrix[aa1].items() if score >= threshold and aa1 != aa2]\n",
    "    return substitution_dict\n",
    "\n",
    "conservative_substitutions_blosum = create_conservative_dict(blosum62)\n",
    "print(conservative_substitutions_blosum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create conservative substitution dictionary based on a threshold\n",
    "def create_conservative_dict(matrix, threshold=1):\n",
    "    substitution_dict = {}\n",
    "    for aa1 in matrix:\n",
    "        substitution_dict[aa1] = [aa2 for aa2, score in matrix[aa1].items() if score >= threshold and aa1 != aa2]\n",
    "    return substitution_dict\n",
    "\n",
    "conservative_substitutions_blosum = create_conservative_dict(blosum62)\n",
    "\n",
    "# Function to apply conservative mutations\n",
    "def conservative_mutate_sequence(seq, substitution_dict, mutation_rate=0.05):\n",
    "    \"\"\"Randomly mutate a sequence using conservative substitutions.\"\"\"\n",
    "    tf.keras.utils.set_random_seed(42)\n",
    "\n",
    "    mutated_seq = list(seq)\n",
    "    for i in range(len(seq)):\n",
    "        if random.random() < mutation_rate:\n",
    "            if seq[i] in substitution_dict and substitution_dict[seq[i]]:\n",
    "                mutated_seq[i] = random.choice(substitution_dict[seq[i]])\n",
    "    return ''.join(mutated_seq)\n",
    "\n",
    "# Function to generate augmented sequences\n",
    "def augment_sequences(sequences, substitution_dict, num_augmentations=3, mutation_rate=0.05):\n",
    "    \"\"\"Generate augmented sequences by applying conservative mutations.\"\"\"\n",
    "    augmented_sequences = []\n",
    "    for seq in sequences:\n",
    "        augmented_sequences.append(seq)  # Include the original sequence\n",
    "        for _ in range(num_augmentations):\n",
    "            mutated_seq = conservative_mutate_sequence(seq, substitution_dict, mutation_rate)\n",
    "            augmented_sequences.append(mutated_seq)\n",
    "    return augmented_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding function\n",
    "def one_hot_encode(seq, vocab):\n",
    "    \"\"\"One-hot encode a sequence based on a given vocabulary.\"\"\"\n",
    "    one_hot = np.zeros((len(seq), len(vocab)), dtype=np.float32)\n",
    "    for i, char in enumerate(seq):\n",
    "        if char in vocab:\n",
    "            one_hot[i, vocab.index(char)] = 1.0\n",
    "    return one_hot\n",
    "\n",
    "# Define your vocabularies\n",
    "aa_vocab = 'ACDEFGHIKLMNPQRSTVWY_'  # 20 amino acids + 1 for gap/unknown\n",
    "structure_vocab = 'he_'  # h for helix, e for sheet, _ for coil\n",
    "\n",
    "# Modified prepare_data function with augmentation\n",
    "def prepare_data(filepath, window_size=13, augment=False, num_augmentations=1, mutation_rate=0.05):\n",
    "    sequences = []\n",
    "    structures = []\n",
    "    current_seq = []\n",
    "    current_struct = []\n",
    "    processing_sequence = False  # Track when inside a sequence block\n",
    "\n",
    "    with open(filepath, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line == '<>':  # Toggle processing flag\n",
    "                if processing_sequence:  # We are ending a sequence block\n",
    "                    if current_seq and current_struct:\n",
    "                        # Augment sequences if required\n",
    "                        seqs_to_encode = [current_seq]\n",
    "                        if augment:\n",
    "                            seqs_to_encode = augment_sequences([current_seq], conservative_substitutions_blosum, num_augmentations, mutation_rate)\n",
    "\n",
    "                        for augmented_seq in seqs_to_encode:\n",
    "                            seq_encoded = one_hot_encode(augmented_seq, aa_vocab)\n",
    "                            struct_encoded = one_hot_encode(current_struct, structure_vocab)\n",
    "\n",
    "                            # Apply sliding window\n",
    "                            for i in range(len(seq_encoded) - window_size + 1):\n",
    "                                window = seq_encoded[i:i + window_size]\n",
    "                                label = struct_encoded[i + window_size // 2]\n",
    "                                sequences.append(window)\n",
    "                                structures.append(label)\n",
    "\n",
    "                    current_seq = []\n",
    "                    current_struct = []\n",
    "                processing_sequence = not processing_sequence\n",
    "                continue\n",
    "\n",
    "            elif 'end' in line:  # Generalized handling for any 'end' marker\n",
    "                continue  # Just skip this line, do not end processing sequence\n",
    "\n",
    "            if processing_sequence:\n",
    "                parts = line.split()\n",
    "                if len(parts) != 2:\n",
    "                    continue  # Skip malformed lines or lines that do not fit expected format\n",
    "                current_seq.append(parts[0])\n",
    "                current_struct.append(parts[1])\n",
    "\n",
    "    return np.array(sequences), np.array(structures)\n",
    "\n",
    "\n",
    "def prepare_data_for_svm(filepath, window_size=13, type='train'):\n",
    "    if type == 'train':\n",
    "        sequences, structures = prepare_data(filepath, augment=True, num_augmentations=1, mutation_rate=0.05)\n",
    "    elif type == 'test':\n",
    "        sequences, structures = prepare_data(filepath, augment=False)\n",
    "    \n",
    "    # Flatten the windows for SVM processing\n",
    "    flat_sequences = sequences.reshape(sequences.shape[0], -1)  # Reshape to (number_of_samples, window_size*features_per_aa)\n",
    "    \n",
    "    return flat_sequences, structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example paths, replace with your actual file pathsin\n",
    "train_path = 'Q_and_s_data/protein-secondary-structure.train.txt'\n",
    "test_path = 'Q_and_s_data/protein-secondary-structure.test.txt'\n",
    "\n",
    "x_train, y_train = prepare_data_for_svm(train_path, 'train')\n",
    "x_test, y_test = prepare_data_for_svm(test_path, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16220, 273) (16220, 3)\n",
      "(3428, 273) (3428, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]\n",
      "Q3 Score (Accuracy): 0.6129\n",
      "Confusion Matrix:\n",
      " [[ 416   63  391]\n",
      " [ 157  226  269]\n",
      " [ 311  136 1459]]\n",
      "MCC for Helix: 0.2937\n",
      "MCC for Sheet: 0.3274\n",
      "MCC for Coil: 0.3394\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, matthews_corrcoef, confusion_matrix\n",
    "\n",
    "# Assuming x_train and y_train are your input and labels loaded from your function\n",
    "# Flatten the one-hot encoded labels to a single dimension\n",
    "y_train_flat = np.argmax(y_train, axis=1)\n",
    "y_test_flat = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Scaling the data\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train.reshape(x_train.shape[0], -1))\n",
    "x_test_scaled = scaler.transform(x_test.reshape(x_test.shape[0], -1))\n",
    "\n",
    "# Initialize and train the SVM\n",
    "svm_model = SVC(kernel='sigmoid', C=2.0, gamma='auto', random_state=42, verbose=True)\n",
    "svm_model.fit(x_train_scaled, y_train_flat)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = svm_model.predict(x_test_scaled)\n",
    "\n",
    "# Compute metrics\n",
    "q3_score = accuracy_score(y_test_flat, y_pred)\n",
    "cm = confusion_matrix(y_test_flat, y_pred)\n",
    "\n",
    "print()\n",
    "print(f\"Q3 Score (Accuracy): {q3_score:.4f}\")\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# Helper function to calculate MCC for each class\n",
    "def calculate_mcc_for_each_class(y_true, y_pred, num_classes):\n",
    "    mcc_scores = []\n",
    "    for class_id in range(num_classes):\n",
    "        # Create binary labels for the current class\n",
    "        y_true_binary = (y_true == class_id).astype(int)\n",
    "        y_pred_binary = (y_pred == class_id).astype(int)\n",
    "        \n",
    "        # Calculate MCC and append to results\n",
    "        mcc = matthews_corrcoef(y_true_binary, y_pred_binary)\n",
    "        mcc_scores.append(mcc)\n",
    "    \n",
    "    return mcc_scores\n",
    "\n",
    "# Calculate MCC for each class\n",
    "mcc_scores = calculate_mcc_for_each_class(y_test_flat, y_pred, 3)\n",
    "\n",
    "# Print the MCC for each class\n",
    "class_labels = ['Helix', 'Sheet', 'Coil']\n",
    "for label, mcc in zip(class_labels, mcc_scores):\n",
    "    print(f\"MCC for {label}: {mcc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio-cwk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
